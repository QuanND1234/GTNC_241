{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i20WfB6lqiUy",
        "outputId": "1ce1b7d8-e07e-49c7-b3d5-8c0c8eeaa8c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15vyI38GkCs40Vv9Yho5C5jWO9TsXimJ5\n",
            "To: /content/list_ward.txt\n",
            "100% 4.18k/4.18k [00:00<00:00, 10.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kPo0d2mqrmlXDiWirLPd6ZFHWDXNRUGV\n",
            "To: /content/list_district.txt\n",
            "100% 3.04k/3.04k [00:00<00:00, 12.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YD1S15-BMmooS7yQyTj8vMA4yiWxNVY2\n",
            "To: /content/list_province.txt\n",
            "100% 728/728 [00:00<00:00, 3.16MB/s]\n"
          ]
        }
      ],
      "source": [
        "# NOTE: you CAN change this cell\n",
        "# If you want to use your own database, download it here\n",
        "# Download DB\n",
        "!rm -rf list_province.txt list_district.txt list_ward.txt\n",
        "# this link is public test\n",
        "!gdown --fuzzy https://drive.google.com/file/d/15vyI38GkCs40Vv9Yho5C5jWO9TsXimJ5/view?usp=drive_link -O list_ward.txt\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1kPo0d2mqrmlXDiWirLPd6ZFHWDXNRUGV/view?usp=drive_link -O list_district.txt\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1YD1S15-BMmooS7yQyTj8vMA4yiWxNVY2/view?usp=drive_link -O list_province.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8znFuZTzwoS",
        "outputId": "dcbf5c12-51c4-4dc2-fb04-ed2f2fd3f4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n"
          ]
        }
      ],
      "source": [
        "# NOTE: you CAN change this cell\n",
        "# Add more to your needs\n",
        "# you must place ALL pip install here\n",
        "!pip install editdistance\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "AodaIxYa32hT"
      },
      "outputs": [],
      "source": [
        "# NOTE: you CAN change this cell\n",
        "# import your library here\n",
        "import time\n",
        "import re\n",
        "import queue"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V1 (Raw Trie + Levenshtein)"
      ],
      "metadata": {
        "id": "FetalHAdbxT5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy_1qPj9aJLt"
      },
      "outputs": [],
      "source": [
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char == ' ': continue\n",
        "            if char not in node.children:\n",
        "                node.children[char] = TrieNode()\n",
        "            node = node.children[char]\n",
        "        node.is_end_of_word = True\n",
        "\n",
        "    def search(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                return False\n",
        "            node = node.children[char]\n",
        "        return node.is_end_of_word\n",
        "\n",
        "    def _search_with_distance(self, node, word, index, current_distance, max_distance, current_word, results):\n",
        "        if current_distance > max_distance:\n",
        "            return\n",
        "\n",
        "        if node.is_end_of_word:\n",
        "            if (current_word != \"\") and (not current_word.startswith(\"_\")):\n",
        "              results.append((current_word, current_distance))\n",
        "            else:\n",
        "              results.append((\"\", current_distance))\n",
        "\n",
        "        if index < len(word):\n",
        "            for char, child_node in node.children.items():\n",
        "                # Check for substitution\n",
        "                if char == word[index]:\n",
        "                    self._search_with_distance(child_node, word, index + 1, current_distance, max_distance, current_word + char, results)\n",
        "                else:\n",
        "                    # Check for substitution and insertion\n",
        "                    self._search_with_distance(child_node, word, index + 1, current_distance + 1, max_distance, current_word + char, results)\n",
        "\n",
        "                    # Check for deletion\n",
        "                    self._search_with_distance(child_node, word, index, current_distance + 1, max_distance, current_word + char, results)\n",
        "\n",
        "        # If we are still within the length of the word, add the character to the current word (insert case)\n",
        "        if index < len(word):\n",
        "            self._search_with_distance(node, word, index + 1, current_distance + 1, max_distance, current_word, results)\n",
        "\n",
        "    def _search_with_distance_dp(self, node, word, index, current_distance, max_distance, current_word, results, memo):\n",
        "        # If we have already computed this state, return from memo\n",
        "        if (index, current_distance, current_word) in memo:\n",
        "            return memo[(index, current_distance, current_word)]\n",
        "\n",
        "        # If the current distance exceeds the allowed max distance, stop the recursion\n",
        "        if current_distance > max_distance:\n",
        "            return\n",
        "\n",
        "        # If this is the end of a word in the Trie, add the current word and distance to the results\n",
        "        if node.is_end_of_word:\n",
        "            if (current_word != \"\") and (not current_word.startswith(\"_\")):\n",
        "                results.append((current_word, current_distance))\n",
        "            else:\n",
        "                results.append((\"\", current_distance))\n",
        "\n",
        "        # If we still have characters left in the word to process\n",
        "        if index < len(word):\n",
        "            for char, child_node in node.children.items():\n",
        "                # Substitution (or match)\n",
        "                if char == word[index]:\n",
        "                    self._search_with_distance_dp(child_node, word, index + 1, current_distance, max_distance, current_word + char, results, memo)\n",
        "                else:\n",
        "                    # Substitution with cost (mismatch)\n",
        "                    self._search_with_distance_dp(child_node, word, index + 1, current_distance + 1, max_distance, current_word + char, results, memo)\n",
        "\n",
        "                    # Deletion (skipping a character in the word)\n",
        "                    self._search_with_distance_dp(child_node, word, index, current_distance + 1, max_distance, current_word + char, results, memo)\n",
        "\n",
        "        # Insertion (adding a character from the Trie without advancing in the word)\n",
        "        if index < len(word):\n",
        "            self._search_with_distance_dp(node, word, index + 1, current_distance + 1, max_distance, current_word, results, memo)\n",
        "\n",
        "        # Memoize the result for this state\n",
        "        memo[(index, current_distance, current_word)] = results\n",
        "\n",
        "    def levenshtein_with_trie(self, word, max_distance, dp=False):\n",
        "        results = []\n",
        "        if dp:\n",
        "            self._search_with_distance_dp(self.root, word, 0, 0, max_distance, \"\", results, {})\n",
        "        else:\n",
        "            self._search_with_distance(self.root, word, 0, 0, max_distance, \"\", results)\n",
        "        results.sort(key=lambda x: x[1])\n",
        "        return results\n",
        "\n",
        "    def _print_trie(self, node, word):\n",
        "        if node.is_end_of_word:\n",
        "            print(word)\n",
        "\n",
        "        for char, child_node in node.children.items():\n",
        "            self._print_trie(child_node, word + char)\n",
        "\n",
        "    def print_trie(self):\n",
        "        print(\"Words in the Trie:\")\n",
        "        self._print_trie(self.root, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtwG3tBDzMLD"
      },
      "outputs": [],
      "source": [
        "# NOTE: you MUST change this cell\n",
        "# New methods / functions must be written under class Solution.\n",
        "class Solution:\n",
        "    def __init__(self):\n",
        "        # list provice, district, ward for private test, do not change for any reason\n",
        "\n",
        "        self.province_path = 'list_province.txt'\n",
        "        self.district_path = 'list_district.txt'\n",
        "        self.ward_path = 'list_ward.txt'\n",
        "        self.root_district = Trie()\n",
        "        self.root_province = Trie()\n",
        "        self.root_ward = Trie()\n",
        "\n",
        "        # Adjustables\n",
        "        self.max_distance = 3\n",
        "        self.stopwords = ['thành phố', 'thị trấn', 'phường', 'huyện', 'tỉnh', 'quận', 'tp', 't.p', 'Tp.', 'tt.', 'tx.', 't.x', 'xã', 'h.', 'x.', 't.', 'q.', 'tx', 'x2']\n",
        "\n",
        "        self.province_data = None\n",
        "        self.district_data = None\n",
        "        self.ward_data = None\n",
        "\n",
        "        self.read_file()\n",
        "        self.build_tree()\n",
        "\n",
        "    def read_file(self):\n",
        "        self.province_data = open(self.province_path, encoding='utf8')\n",
        "        self.district_data = open(self.district_path, encoding='utf8')\n",
        "        self.ward_data = open(self.ward_path, encoding='utf8')\n",
        "\n",
        "    def build_tree(self):\n",
        "        for i in self.district_data:\n",
        "            self.root_district.insert(i.replace('\\n', ''))\n",
        "        for i in self.province_data:\n",
        "            self.root_province.insert(i.replace('\\n', ''))\n",
        "        for i in self.ward_data:\n",
        "            self.root_ward.insert(i.replace('\\n', ''))\n",
        "        # self.root_ward.print_trie()\n",
        "        # self.root_province.print_trie()\n",
        "        # self.root_district.print_trie()\n",
        "\n",
        "    def remove_stopwords_from_address(self, address: str):\n",
        "        chunks = address.split(\",\")\n",
        "        clear_chunks = []\n",
        "\n",
        "        for chunk in chunks:\n",
        "            words:str = chunk.split(\" \")\n",
        "            stopword_clear_words = []\n",
        "            for word in words:\n",
        "                for stopword in self.stopwords:\n",
        "                    if stopword is word:\n",
        "                        break\n",
        "                    elif word.lower().startswith(stopword):\n",
        "                        word = word[len(stopword):]\n",
        "                    elif word.lower().endswith(stopword):\n",
        "                        word = word[:len(word) - len(stopword)]\n",
        "                striped_word = re.sub(r'\\W+', '', word.strip())\n",
        "                if len(striped_word) > 1:\n",
        "                    stopword_clear_words.append(striped_word)\n",
        "            clear_chunks.append(\"\".join(stopword_clear_words))\n",
        "            # TODO: Remove First Letter of Stopword (X, T, H) that follows with a Constant\n",
        "        # print(\"After sanitizing: \", clear_chunks)\n",
        "        return clear_chunks\n",
        "\n",
        "    def find_nearest_string(self, trie: Trie, text: str, dp=False):\n",
        "        result = trie.levenshtein_with_trie(text, self.max_distance, dp)\n",
        "        filtered_result = list(filter(lambda item: len(item[0]) > 1, result))\n",
        "        if filtered_result:\n",
        "            nearest_string = filtered_result[0]\n",
        "        else:\n",
        "            # Handle the case where no suitable string is found\n",
        "            nearest_string = (\"\", float('inf'))  # or any other appropriate default\n",
        "        return nearest_string\n",
        "\n",
        "    def add_space_to_pascal_case(self, text):\n",
        "        # Use regex to find uppercase letters and add a space before each (except the first one)\n",
        "        spaced_text = re.sub(r'(?<!^)([A-Z])', r' \\1', text)\n",
        "        return spaced_text\n",
        "\n",
        "    def process(self, s: str):\n",
        "        # write your process string here\n",
        "        sanitized_address = self.remove_stopwords_from_address(s)\n",
        "        # TODO: code to split string\n",
        "        ward = self.find_nearest_string(self.root_province, sanitized_address[0], dp=True)[0] if len(sanitized_address) > 0 else \"\"\n",
        "        district = self.find_nearest_string(self.root_district, sanitized_address[1], dp=True)[0] if len(sanitized_address) > 1 else \"\"\n",
        "        province = self.find_nearest_string(self.root_province, sanitized_address[2], dp=True)[0] if len(sanitized_address) > 2 else \"\"\n",
        "        result = {\n",
        "            \"province\": self.add_space_to_pascal_case(province),\n",
        "            \"district\": self.add_space_to_pascal_case(district),\n",
        "            \"ward\": self.add_space_to_pascal_case(ward),\n",
        "        }\n",
        "        # print(\"Search result: \", result)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V2 (BK-Tree)"
      ],
      "metadata": {
        "id": "iTAiINF6b4sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAXN = 10000\n",
        "TOL = 5\n",
        "LEN = 10\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, x=None):\n",
        "        self.word = x\n",
        "        self.next = [0] * 2000\n",
        "\n",
        "class BKTree:\n",
        "    def __init__(self, maxn=MAXN, tol=TOL, len=LEN):\n",
        "        self.root = Node()\n",
        "        self.ptr = 0\n",
        "        self.tree = [Node() for _ in range(MAXN)]\n",
        "\n",
        "    def add(self, curr):\n",
        "      def _add(root, curr):\n",
        "        if not root.word:\n",
        "            root.word = curr.word\n",
        "            root.next = curr.next\n",
        "            return\n",
        "\n",
        "        dist = edit_distance(curr.word, root.word)\n",
        "        if not self.tree[root.next[dist]] or not self.tree[root.next[dist]].word:\n",
        "            self.ptr += 1\n",
        "            self.tree[self.ptr] = curr\n",
        "            root.next[dist] = self.ptr\n",
        "        else:\n",
        "            _add(self.tree[root.next[dist]], curr)\n",
        "\n",
        "      return _add(self.root, curr)\n",
        "\n",
        "    def search(self, s):\n",
        "      def _search(root, s):\n",
        "        ret = []\n",
        "        if not root or not root.word:\n",
        "            return ret\n",
        "\n",
        "        dist = edit_distance(root.word, s)\n",
        "        if dist <= TOL:\n",
        "            ret.append(root.word)\n",
        "\n",
        "        start = dist - TOL if dist - TOL > 0 else 1\n",
        "        while start <= dist + TOL:\n",
        "            tmp = _search(self.tree[root.next[start]], s)\n",
        "            ret += tmp\n",
        "            start += 1\n",
        "        return ret # return pair (word, distance)\n",
        "\n",
        "      return _search(self.root, s)\n",
        "\n",
        "def edit_distance(a, b):\n",
        "    m, n = len(a), len(b)\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "          if a[i - 1] != b[j - 1]:\n",
        "                dp[i][j] = min(\n",
        "                    dp[i - 1][j] + 1,  # deletion\n",
        "                    dp[i][j - 1] + 1,  # insertion\n",
        "                    dp[i - 1][j - 1] + 2  # replacement\n",
        "                )\n",
        "          else:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "    return dp[m][n]\n",
        "\n",
        "#dictionary words\n",
        "if __name__ == \"__main__\":\n",
        "    tree = BKTree()\n",
        "    dictionary = [\"hell\", \"help\", \"shell\", \"smell\", \"fell\", \"felt\", \"oops\", \"pop\", \"oouch\", \"halt\"]\n",
        "    sz = len(dictionary)\n",
        "    #adding dict[] words on to tree\n",
        "    for i in range(sz):\n",
        "        tmp = Node(dictionary[i])\n",
        "        tree.add(tmp)\n",
        "\n",
        "    w1 = \"ops\"\n",
        "    match1 = tree.search(w1)\n",
        "    print(\"similar words in dictionary for\", w1, \": \")\n",
        "    for word in match1:\n",
        "        print(word, end=\" \")\n",
        "    print()\n",
        "\n",
        "    w2 = \"helt\"\n",
        "    match2 = tree.search(w2)\n",
        "    print(\"similar words in dictionary for\", w2, \": \")\n",
        "    for word in match2:\n",
        "        print(word, end=\" \")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MPHh5hPcF9l",
        "outputId": "99fc0ba5-398f-4b8d-b7a5-f8bd55a5c231"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similar words in dictionary for ops : \n",
            "help pop oops \n",
            "similar words in dictionary for helt : \n",
            "hell shell help fell smell felt halt \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def generate_initial_combinations(text):\n",
        "    \"\"\"Generates all possible initial combinations of a string.\n",
        "\n",
        "    Args:\n",
        "        text: The input string.\n",
        "\n",
        "    Returns:\n",
        "        A list of all possible initial combinations.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "\n",
        "    # Generate all combinations of full words and initials for each word\n",
        "    word_combinations = []\n",
        "    for word in words:\n",
        "        word_combinations.append([word, word[0] + \".\"])  # Add full word and initial with period\n",
        "\n",
        "    # Generate all possible combinations using itertools.product\n",
        "    all_combinations = list(itertools.product(*word_combinations))\n",
        "\n",
        "    # Join the combinations into strings and return\n",
        "    initial_combinations = [\"\".join(comb) for comb in all_combinations]\n",
        "    return initial_combinations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXm0_Wk39YxF",
        "outputId": "ae13befa-43a8-473d-c740-931eae722816"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NewYorkHekki', 'NewYorkH.', 'NewY.Hekki', 'NewY.H.', 'N.YorkHekki', 'N.YorkH.', 'N.Y.Hekki', 'N.Y.H.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: you MUST change this cell\n",
        "# New methods / functions must be written under class Solution.\n",
        "import re\n",
        "import string\n",
        "import unidecode\n",
        "\n",
        "class Solution:\n",
        "    def __init__(self):\n",
        "        # list provice, district, ward for private test, do not change for any reason\n",
        "\n",
        "        self.province_path = 'list_province.txt'\n",
        "        self.district_path = 'list_district.txt'\n",
        "        self.ward_path = 'list_ward.txt'\n",
        "        self.root_district = BKTree()\n",
        "        self.root_province = BKTree()\n",
        "        self.root_ward = BKTree()\n",
        "\n",
        "        # Adjustables\n",
        "        self.max_distance = 3\n",
        "        self.stopwords = ['tha6nhpho', 'thanhpho', 'thanh pho', 'thi xa', 'thixa' ,'thi tran', 'phuong', 'huyen', \"hyen\", 'tinh', 'quan ', 'tp', 't.p', 'tp.', 'tt.', 'tx.', 't.x.', 't.x', 'tnh', 'tg.', 'tin', 'tt', 'tt', 'xa', 'h.', 'x.', 't.', 'q.', 'tx', 'x2', 'h ']\n",
        "        self.stopwords_dict = {\n",
        "            \"province\": ['tha6nhpho', \"thanhpho\", \"thanhfho\", \"tinh\", 't.pho', \"tp\", \"t.p\", \"Tp.\", \"tnh\", \"t.\", \" t \", \"tin\", \"tnh\", 'tg.'],\n",
        "            \"district\": [\"thanh pho\", 'tha6nhpho', \"thanhfho\", \"thanhpho\", \"tp\", 't.pho', \"t.p\", \"Tp.\", \"tnh\", \"huyen\", \"quan\", \"q.\", \"h.\", \" h \", \" q \", 'thi xa', 'thixa', 'hixa', 'ixa'],\n",
        "            \"ward\": [\"phuong\", \"phg\", \"ph\", \"p.\", \"xa\", \"x.\", \" p \", \" x \", \"thitran\", \"tt\", \"tt.\", \"thitr\", \"thtran\", \"thtr\", \"f.\"]\n",
        "        }\n",
        "\n",
        "        self.province_sanitized_map = dict()\n",
        "        self.district_sanitized_map = dict()\n",
        "        self.ward_sanitized_map = dict()\n",
        "        self.whitelisted_province = []\n",
        "        self.whitelisted_district = []\n",
        "        self.whitelisted_ward = []\n",
        "\n",
        "        self.read_file()\n",
        "        self.build_tree()\n",
        "\n",
        "    def remove_special_characters(self, text, remove_space=True, lowercase=True):\n",
        "        text = unidecode.unidecode(text)  # Loại bỏ dấu\n",
        "        # pattern = f\"[{re.escape(string.punctuation)}]\"\n",
        "        # text = re.sub(pattern, \"\", text)  # Loại bỏ ký tự đặc biệt\n",
        "        if remove_space: text = re.sub(r'\\s+', '', text)  # Loại bỏ khoảng trắng\n",
        "        if lowercase: text = text.lower()               # In thường\n",
        "        return text\n",
        "\n",
        "    def read_file(self):\n",
        "        province_data = open(self.province_path, encoding='utf8')\n",
        "        district_data = open(self.district_path, encoding='utf8')\n",
        "        ward_data = open(self.ward_path, encoding='utf8')\n",
        "        district_prefixes = [\"quan\", \"q\", \"q0\", \"qn\"]\n",
        "        ward_prefixes = [\"phuong\", \"phuong0\", \"p.\", \"f\"]\n",
        "\n",
        "        for line in province_data:\n",
        "            data = line.replace('\\n', '')\n",
        "            self.province_sanitized_map[self.remove_special_characters(data)] = data\n",
        "            # initials = generate_initial_combinations(self.remove_special_characters(data, remove_space=False))\n",
        "            # for initial in initials:\n",
        "            #   self.province_sanitized_map.setdefault(initial, data)\n",
        "\n",
        "        for line in district_data:\n",
        "            data = line.replace('\\n', '')\n",
        "            s_data = self.remove_special_characters(data)\n",
        "            self.district_sanitized_map[s_data] = data\n",
        "            if data.isdigit():\n",
        "              for prefix in district_prefixes:\n",
        "                self.district_sanitized_map.update({f\"{prefix}{s_data}\": data})\n",
        "\n",
        "        for line in ward_data:\n",
        "            data = line.replace('\\n', '')\n",
        "            s_data = self.remove_special_characters(data)\n",
        "            self.ward_sanitized_map[self.remove_special_characters(data)] = data\n",
        "            if data.isdigit():\n",
        "              for prefix in ward_prefixes:\n",
        "                self.ward_sanitized_map.update({f\"{prefix}{s_data}\": data})\n",
        "\n",
        "        province_custom_map = {\n",
        "            \"t.t.h\": \"Thừa Thiên Huế\",\n",
        "            \"thua.t.hue\": \"Thừa Thiên Huế\",\n",
        "            \"thua.thien.hue\": \"Thừa Thiên Huế\",\n",
        "            \"hcm\": \"Hồ Chí Minh\",\n",
        "            \"ho.chi.minh\": \"Hồ Chí Minh\",\n",
        "            \"h.c.m\": \"Hồ Chí Minh\",\n",
        "            \"h.c.m.\": \"Hồ Chí Minh\"\n",
        "        }\n",
        "        self.province_sanitized_map.update(province_custom_map)\n",
        "\n",
        "\n",
        "    def build_tree(self):\n",
        "        for district in self.district_sanitized_map.keys():\n",
        "            district_node = Node(self.remove_special_characters(district))\n",
        "            self.root_district.add(district_node)\n",
        "        for province in self.province_sanitized_map.keys():\n",
        "            province_node = Node(self.remove_special_characters(province))\n",
        "            self.root_province.add(province_node)\n",
        "        for ward in self.ward_sanitized_map.keys():\n",
        "            ward_node = Node(self.remove_special_characters(ward))\n",
        "            self.root_ward.add(ward_node)\n",
        "\n",
        "\n",
        "    def remove_stopwords_from_address(self, address: str):\n",
        "        chunks = address.lower().split(\",\")\n",
        "\n",
        "        clear_chunks = []\n",
        "\n",
        "        # CONSTANTS\n",
        "        HEAD_SW_SIZE = 7\n",
        "        DIST_ALLOWED = 2\n",
        "        WINDOW_ALLOWED = 9\n",
        "        OFFSET = 1\n",
        "\n",
        "        self.whitelisted_province = filter(lambda x: len(x) >= WINDOW_ALLOWED - DIST_ALLOWED, self.province_sanitized_map.keys())\n",
        "        self.whitelisted_district = filter(lambda x: len(x) >= WINDOW_ALLOWED - DIST_ALLOWED, self.district_sanitized_map.keys())\n",
        "        self.whitelisted_ward = filter(lambda x: len(x) >= WINDOW_ALLOWED - DIST_ALLOWED, self.ward_sanitized_map.keys())\n",
        "\n",
        "        def should_elim_prefix_stopword(chunk, stopword):\n",
        "            head = chunk[:HEAD_SW_SIZE]\n",
        "            return (len(chunk) >= 1.75*len(stopword) or chunk[len(stopword):].isdigit()) and (chunk.startswith(stopword) or edit_distance(head, stopword)) <= DIST_ALLOWED\n",
        "\n",
        "        # Right to left\n",
        "        # NOTE 1: MUST sanitize the chunk before adding to clear_chunks\n",
        "        # NOTE 2: MUST check the WARD chunk carefully\n",
        "        # A. COMMA >= 2\n",
        "        if len(chunks) >= 3:\n",
        "            for i in range(len(chunks) - 1, -1, -1):\n",
        "                # Basic sanitization\n",
        "                chunk = self.remove_special_characters(chunks[i])\n",
        "                # Remove stopwords\n",
        "                for stopword in self.stopwords:\n",
        "                    if should_elim_prefix_stopword(chunk, stopword):\n",
        "                        chunk = chunk[len(stopword):]\n",
        "                        break\n",
        "                # We are in the Province chunk, and it is longer than expected -> may contain District/ Ward\n",
        "                if i == 2:\n",
        "                    jump_to_next_chunk = False\n",
        "                    if len(chunk) > WINDOW_ALLOWED:\n",
        "                        is_whitelist = False\n",
        "                        # Sanit. A.1: Contains Stop word\n",
        "                        for sw_district in self.stopwords_dict[\"province\"]:\n",
        "                            if sw_district in chunk:\n",
        "                                jump_to_next_chunk = True\n",
        "                                sp = chunk.split(sw_district)\n",
        "                                province = sp[1]\n",
        "                                district = sp[0]\n",
        "                                if len(province) < 4:\n",
        "                                  clear_chunks.append(\"\")\n",
        "                                  break\n",
        "                                clear_chunks.append(province)\n",
        "                                if len(district) < 3 and not district.isdigit(): break\n",
        "                                clear_chunks.append(district) if len(district) <= WINDOW_ALLOWED else clear_chunks.append(district[-WINDOW_ALLOWED:])\n",
        "                                break\n",
        "                        if jump_to_next_chunk: continue\n",
        "                        else:\n",
        "                          # Sanit. A.2: Contains Whitelist word\n",
        "                          for wl_province in self.whitelisted_province:\n",
        "                              if edit_distance(chunk, wl_province) <= DIST_ALLOWED:\n",
        "                                  is_whitelist = True\n",
        "                                  province = self.remove_special_characters(wl_province)\n",
        "                                  clear_chunks.append(province)\n",
        "                                  break\n",
        "                          # Sanit. A.3: Not Whitelisted\n",
        "                          if not is_whitelist:\n",
        "                              province = self.remove_special_characters(chunk[-len(chunk)//2 - OFFSET:])\n",
        "                              district = self.remove_special_characters(chunk[:-len(chunk)//2 + OFFSET])\n",
        "                              if province != district:\n",
        "                                  jump_to_next_chunk = True\n",
        "                                  if len(province) < 3: continue\n",
        "                                  clear_chunks.append(province)\n",
        "                                  if len(district) < 3 and not district.isdigit(): continue\n",
        "                                  clear_chunks.append(district) if len(district) <= WINDOW_ALLOWED else clear_chunks.append(district[-WINDOW_ALLOWED:])\n",
        "                                  if len(clear_chunks) == 3: return clear_chunks\n",
        "                    else:\n",
        "                        clear_chunks.append(chunk)\n",
        "                # We are in the District chunk, and it is longer than expected -> may contain Ward\n",
        "                if i == 1:\n",
        "                    jump_to_next_chunk = False\n",
        "                    if len(chunk) > WINDOW_ALLOWED:\n",
        "                        is_whitelist = False\n",
        "                        # Sanit. A.1: Contains Stop word\n",
        "                        for sw_district in self.stopwords_dict[\"district\"]:\n",
        "                            if sw_district in chunk:\n",
        "                                jump_to_next_chunk = True\n",
        "                                sp = chunk.split(sw_district)\n",
        "                                district = self.remove_special_characters(sp[1])\n",
        "                                ward = self.remove_special_characters(sp[0])\n",
        "                                print(district, ward)\n",
        "                                if len(district) < 3 and not district.isdigit(): break\n",
        "                                clear_chunks.append(district)\n",
        "                                if len(ward) < 3 and not ward.isdigit(): break\n",
        "                                clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                                if len(clear_chunks) == 3: return clear_chunks\n",
        "                                break\n",
        "                        if jump_to_next_chunk: continue\n",
        "                        else:\n",
        "                          # Sanit. A.2: Contains Whitelist word\n",
        "                          for wl_district in self.whitelisted_district:\n",
        "                              if edit_distance(chunk, wl_district) <= DIST_ALLOWED:\n",
        "                                  is_whitelist = True\n",
        "                                  district = self.remove_special_characters(wl_district)\n",
        "                                  break\n",
        "                          # Sanit. A.3: Not Whitelisted\n",
        "                          if not is_whitelist:\n",
        "                              district = self.remove_special_characters(chunk[-len(chunk)//2 - OFFSET:])\n",
        "                              ward = self.remove_special_characters(chunk[:-len(chunk)//2 + OFFSET])\n",
        "                              if district != ward:\n",
        "                                  jump_to_next_chunk = True\n",
        "                                  if len(district) < 3 and not district.isdigit(): continue\n",
        "                                  clear_chunks.append(district)\n",
        "                                  if len(ward) < 3 and not ward.isdigit(): continue\n",
        "                                  clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                                  if len(clear_chunks) == 3: return clear_chunks\n",
        "                    else:\n",
        "                        for sw_district in self.stopwords_dict[\"district\"]:\n",
        "                            if sw_district in chunk:\n",
        "                                jump_to_next_chunk = True\n",
        "                                sp = chunk.split(sw_district)\n",
        "                                district = self.remove_special_characters(sp[1])\n",
        "                                ward = self.remove_special_characters(sp[0])\n",
        "                                print(district, ward)\n",
        "                                if len(district) < 3 and not district.isdigit(): break\n",
        "                                clear_chunks.append(district)\n",
        "                                if len(ward) < 3 and not ward.isdigit(): break\n",
        "                                clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                                if len(clear_chunks) == 3: return clear_chunks\n",
        "                                break\n",
        "                        district = self.remove_special_characters(chunk)\n",
        "                    if not jump_to_next_chunk: clear_chunks.append(district)\n",
        "                    continue\n",
        "                # Sanit. 3.2: We are in the Ward chunk, and it is longer than expected\n",
        "                if len(clear_chunks) == 3: return clear_chunks\n",
        "                if i == 0:\n",
        "                    # Edge Case: Numeric Ward\n",
        "                    if len(chunk) < 4: ward = chunk[1:] # Pxx\n",
        "                    elif len(chunk) > WINDOW_ALLOWED:\n",
        "                        is_whitelist = False\n",
        "                        word, min_dist = \"\", float('inf')\n",
        "                        for wl_ward in self.whitelisted_ward:\n",
        "                            dist = edit_distance(chunk, wl_ward)\n",
        "                            if dist <= DIST_ALLOWED and dist < min_dist:\n",
        "                                min_dist = dist\n",
        "                                word = wl_ward\n",
        "                                is_whitelist = True\n",
        "                        if is_whitelist: ward = self.remove_special_characters(word)\n",
        "                        else: ward = self.remove_special_characters(chunk[-WINDOW_ALLOWED:])\n",
        "                    else:\n",
        "                        ward = self.remove_special_characters(chunk)\n",
        "                    clear_chunks.append(ward)\n",
        "                if i > 2:\n",
        "                    clear_chunks.append(chunk)\n",
        "            return clear_chunks\n",
        "        # B. COMMA = 1 (lack 1 comma)\n",
        "        elif len(chunks) == 2:\n",
        "          # B.1 Lack of comma to separate province and district\n",
        "          ## Identify: If length of Province > WINDOW_ALLOWED and not in whitelist province\n",
        "          if len(chunks[1]) > WINDOW_ALLOWED - 1:\n",
        "            print(1)\n",
        "            # Whitelist Province flow\n",
        "            is_whitelist_province = False\n",
        "            # Remove stopwords from the Province\n",
        "            chunk1 = self.remove_special_characters(chunks[1])\n",
        "            for stopword in self.stopwords_dict[\"province\"]:\n",
        "                if should_elim_prefix_stopword(chunk1, stopword):\n",
        "                    chunk1 = chunk1[len(stopword):]\n",
        "                    break\n",
        "            print(chunk1)\n",
        "            word, min_dist = \"\", float('inf')\n",
        "            for wl_province in self.whitelisted_province:\n",
        "                dist = edit_distance(chunk1, wl_province)\n",
        "                if dist <= DIST_ALLOWED and dist < min_dist:\n",
        "                    is_whitelist_province = True\n",
        "                    word = wl_province\n",
        "                    min_dist = dist\n",
        "            if is_whitelist_province:\n",
        "                province = self.remove_special_characters(word)\n",
        "                clear_chunks.append(province)\n",
        "                # If we can find a stopword, we can split from it\n",
        "                is_separable_by_district_sw = False\n",
        "                # Remove stopwords from the Ward & District\n",
        "                chunk = self.remove_special_characters(chunks[0])\n",
        "                for stopword in self.stopwords_dict[\"district\"] + self.stopwords_dict[\"ward\"]:\n",
        "                    if should_elim_prefix_stopword(chunk, stopword):\n",
        "                        chunk = chunk[len(stopword):]\n",
        "                        break\n",
        "                for stopword in self.stopwords_dict[\"district\"]:\n",
        "                    if stopword in chunk:\n",
        "                        is_separable_by_district_sw = True\n",
        "                        anchor = chunk.rfind(stopword)\n",
        "                        if anchor == len(chunk) - len(stopword): # stopword is at the end -> not an actual stopword\n",
        "                            if len(chunk) >= WINDOW_ALLOWED:\n",
        "                                district = chunk[-len(chunk)//2 - OFFSET:]\n",
        "                                ward = chunk[:-len(chunk)//2 + OFFSET]\n",
        "                                clear_chunks.append(district)\n",
        "                                clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                                break\n",
        "                            clear_chunks.append(chunk)\n",
        "                            break\n",
        "                        district = self.remove_special_characters(chunk[anchor+len(stopword):]) # district part\n",
        "                        ward = self.remove_special_characters(chunk[:anchor]) # ward part\n",
        "                        clear_chunks.append(district)\n",
        "                        if len(ward) < 2: break\n",
        "                        clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                        break\n",
        "                # Else, we can split from the last WINDOW_ALLOWED chars\n",
        "                if not is_separable_by_district_sw:\n",
        "                  if len(chunk) > WINDOW_ALLOWED:\n",
        "                      district = chunk[-len(chunk)//2 - OFFSET:]\n",
        "                      ward = chunk[:-len(chunk)//2 + OFFSET]\n",
        "                      clear_chunks.append(district)\n",
        "                      clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                  else: clear_chunks.append(chunk)\n",
        "                return clear_chunks\n",
        "            # Non Whitelist Province flow\n",
        "            # If we can find a stopword, we can split from it\n",
        "            is_separable_by_province_sw = False\n",
        "            for stopword in self.stopwords_dict[\"province\"]:\n",
        "                if stopword in chunks[1]:\n",
        "                    is_separable_by_province_sw = True\n",
        "                    anchor = chunks[1].rfind(stopword)\n",
        "                    province = self.remove_special_characters(chunks[1][anchor+len(stopword):]) # province part\n",
        "                    district = self.remove_special_characters(chunks[1][:anchor]) # district part\n",
        "                    clear_chunks.append(province)\n",
        "                    if len(district) > 2 and district not in self.whitelisted_district: clear_chunks.append(district)\n",
        "            # Else, we can split from the last WINDOW_ALLOWED chars\n",
        "            if not is_separable_by_province_sw:\n",
        "              chunk = self.remove_special_characters(chunks[1])\n",
        "              province = chunk[-len(chunk)//2 - OFFSET:]\n",
        "              district = chunk[:-len(chunk)//2 + OFFSET]\n",
        "              clear_chunks.append(province)\n",
        "              if len(district) > 2 and district not in self.whitelisted_district: clear_chunks.append(district) # Filter trash words\n",
        "            # Sanit. 3: We are in the Ward chunk, and it is longer than expected\n",
        "            if len(chunks[0]) > WINDOW_ALLOWED:\n",
        "              chunk = self.remove_special_characters(chunks[0])\n",
        "              is_whitelist = False\n",
        "              for wl_ward in self.whitelisted_ward:\n",
        "                  if edit_distance(chunk, wl_ward) <= DIST_ALLOWED:\n",
        "                      is_whitelist = True\n",
        "                      next = self.remove_special_characters(wl_ward)\n",
        "                      break\n",
        "              if not is_whitelist: next = self.remove_special_characters(chunk[-WINDOW_ALLOWED:])\n",
        "            else:\n",
        "              next = self.remove_special_characters(chunks[0])\n",
        "            clear_chunks.append(next)\n",
        "            return clear_chunks\n",
        "\n",
        "          # B.2 Lack of comma to separate ward and province\n",
        "          ## Identify: If length of District > WINDOW_ALLOWED and not in whitelisted districts\n",
        "          elif len(chunks[0]) > WINDOW_ALLOWED - 1:\n",
        "            print(2)\n",
        "            # Append Province chunk first\n",
        "            chunk = self.remove_special_characters(chunks[1])\n",
        "            for stopword in self.stopwords_dict[\"province\"]:\n",
        "                if should_elim_prefix_stopword(chunk, stopword):\n",
        "                    chunks[1] = chunks[1][len(stopword):]\n",
        "                    break\n",
        "            clear_chunks.append(self.remove_special_characters(chunks[1]))\n",
        "\n",
        "            # Remove stopwords from the Ward & District\n",
        "            chunk = self.remove_special_characters(chunks[0])\n",
        "            for stopword in self.stopwords_dict[\"district\"] + self.stopwords_dict[\"ward\"]:\n",
        "                if should_elim_prefix_stopword(chunk, stopword):\n",
        "                    chunks[0] = chunks[0][len(stopword):]\n",
        "                    break\n",
        "\n",
        "            # If we can find a stopword, we can split from it\n",
        "            is_separable_by_district_sw = False\n",
        "            chunk = self.remove_special_characters(chunks[0])\n",
        "            for stopword in self.stopwords_dict[\"district\"]:\n",
        "                if stopword in chunk:\n",
        "                    is_separable_by_district_sw = True\n",
        "                    anchor = chunk.rfind(stopword)\n",
        "                    district = self.remove_special_characters(chunk[anchor+len(stopword):]) # district part\n",
        "                    ward = self.remove_special_characters(chunk[:anchor]) # ward part\n",
        "                    clear_chunks.append(district)\n",
        "                    clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "            # Else, we can split from the last WINDOW_ALLOWED chars\n",
        "            if not is_separable_by_district_sw:\n",
        "              chunk = self.remove_special_characters(chunk)\n",
        "              district = chunk[-len(chunk)//2 - OFFSET:]\n",
        "              ward = chunk[:-len(chunk)//2 + OFFSET]\n",
        "              clear_chunks.append(district)\n",
        "              clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "            return clear_chunks\n",
        "\n",
        "        # C. COMMA = 0\n",
        "        elif len(chunks) == 1:\n",
        "          # Flags\n",
        "          is_separable_by_province_sw = False\n",
        "          is_separable_by_district_sw = False\n",
        "          chunks[0] = self.remove_special_characters(chunks[0])\n",
        "          for stopword in self.stopwords_dict[\"province\"]:\n",
        "              if stopword in chunks[0]:\n",
        "                  is_separable_by_province_sw = True\n",
        "                  anchor = chunks[0].rfind(stopword)\n",
        "                  province = self.remove_special_characters(chunks[0][anchor+len(stopword):]) # province part\n",
        "                  ward_district = self.remove_special_characters(chunks[0][:anchor]) # district part\n",
        "                  clear_chunks.append(province)\n",
        "\n",
        "                  for s_stopword in self.stopwords_dict[\"district\"]:\n",
        "                      if s_stopword in ward_district:\n",
        "                          is_separable_by_district_sw = True\n",
        "                          anchor = ward_district.rfind(s_stopword)\n",
        "                          district = self.remove_special_characters(ward_district[anchor+len(s_stopword):]) # district part\n",
        "                          ward = self.remove_special_characters(ward_district[:anchor]) # ward part\n",
        "                          if len(district) < 3: return clear_chunks\n",
        "                          clear_chunks.append(district)\n",
        "                          if len(ward) < 3: return clear_chunks\n",
        "                          clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                          return clear_chunks\n",
        "                  if not is_separable_by_district_sw:\n",
        "                      chunk = self.remove_special_characters(ward_district)\n",
        "                      district = chunk[-WINDOW_ALLOWED:]\n",
        "                      ward = chunk[:-WINDOW_ALLOWED]\n",
        "                      if len(district) < 3: return clear_chunks\n",
        "                      clear_chunks.append(district)\n",
        "                      if len(ward) < 3: return clear_chunks\n",
        "                      clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                  return clear_chunks\n",
        "          if not is_separable_by_province_sw:\n",
        "              province = chunks[0][-WINDOW_ALLOWED:]\n",
        "              ward_district = chunks[0][:-WINDOW_ALLOWED]\n",
        "              clear_chunks.append(province)\n",
        "              for s_stopword in self.stopwords_dict[\"district\"]:\n",
        "                  if s_stopword in ward_district:\n",
        "                      is_separable_by_district_sw = True\n",
        "                      anchor = ward_district.rfind(s_stopword)\n",
        "                      district = self.remove_special_characters(ward_district[anchor+len(s_stopword):]) # district part\n",
        "                      ward = self.remove_special_characters(ward_district[:anchor]) # ward part\n",
        "                      if len(district) < 3: return clear_chunks\n",
        "                      clear_chunks.append(district)\n",
        "                      if len(ward) < 3: return clear_chunks\n",
        "                      clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "                      return clear_chunks\n",
        "              if not is_separable_by_district_sw:\n",
        "                  chunk = self.remove_special_characters(ward_district)\n",
        "                  district = chunk[-WINDOW_ALLOWED:]\n",
        "                  ward = chunk[:-WINDOW_ALLOWED]\n",
        "                  if len(district) < 3: return clear_chunks\n",
        "                  clear_chunks.append(district)\n",
        "                  if len(ward) < 3: return clear_chunks\n",
        "                  clear_chunks.append(ward) if len(ward) <= WINDOW_ALLOWED else clear_chunks.append(ward[-WINDOW_ALLOWED:])\n",
        "              return clear_chunks\n",
        "        return [\"\", \"\", \"\"]\n",
        "\n",
        "    def find_nearest_string(self, tree: BKTree, text: str):\n",
        "        # Early exit if text is empty or too short and non-numeric.\n",
        "        if not text or (len(text) < 3 and not text.isdigit()):\n",
        "            return \"\"\n",
        "        result = tree.search(text)\n",
        "        result.sort(key=lambda x: edit_distance(x, text))\n",
        "        ans = result[0] if len(result) > 0 else \"\"\n",
        "        # Early exit if ans is empty or too short and non-numeric.\n",
        "        if not ans or (len(text) < 3 and not text.isdigit()):\n",
        "            return \"\"\n",
        "        return ans\n",
        "\n",
        "    def process(self, s: str):\n",
        "        # write your process string here\n",
        "        sanitized_address = self.remove_stopwords_from_address(s)\n",
        "        # Final Normalization\n",
        "        while len(sanitized_address) < 3: sanitized_address.append(\"\")\n",
        "        if len(sanitized_address) > 3: sanitized_address = sanitized_address[:3]\n",
        "        # TODO: code to split string\n",
        "        ward = self.find_nearest_string(self.root_ward, sanitized_address[2]) if len(sanitized_address) > 2 else \"\"\n",
        "        district = self.find_nearest_string(self.root_district, sanitized_address[1]) if len(sanitized_address) > 1 else \"\"\n",
        "        province = self.find_nearest_string(self.root_province, sanitized_address[0]) if len(sanitized_address) > 0 else \"\"\n",
        "        result = {\n",
        "            \"province\": self.province_sanitized_map[province] if province != \"\" else \"\",\n",
        "            \"district\": self.district_sanitized_map[district] if district != \"\" else \"\",\n",
        "            \"ward\": self.ward_sanitized_map[ward] if ward != \"\" else \"\"\n",
        "        }\n",
        "        # TODO: only return result\n",
        "        return result, sanitized_address"
      ],
      "metadata": {
        "id": "obnm2eofcDX1"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sdb3ddTr1Jz",
        "outputId": "73791db3-bf1b-4e7b-e184-d39beca1442f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PBt3U9I3EH885CDhcXspebyKI5Vw6uLB\n",
            "To: /content/test.json\n",
            "\r  0% 0.00/79.4k [00:00<?, ?B/s]\r100% 79.4k/79.4k [00:00<00:00, 64.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# NOTE: DO NOT change this cell\n",
        "# This cell is for downloading private test\n",
        "!rm -rf test.json\n",
        "# this link is public test\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1PBt3U9I3EH885CDhcXspebyKI5Vw6uLB/view?usp=sharing -O test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "hjO6FFcA0DYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ea901f-6f92-48b4-a49b-e61ef698d7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "tuyenquang\n",
            "1 dakao\n",
            "1\n",
            "yenmyhungyen\n",
            "Input:  Khu phố 4 Thị trấn, Dương Minh Châu, Tây Ninh\n",
            "Sanitized:  ['tayninh', 'duongminhchau', 'o4thitran']\n",
            "Result:  {'province': 'Tây Ninh', 'district': 'Dương Minh Châu', 'ward': 'Thới An'}\n",
            "Answer:  {'province': 'Tây Ninh', 'district': 'Dương Minh Châu', 'ward': ''}\n",
            "----\n",
            "1\n",
            "thaibinh\n",
            "2\n",
            "1\n",
            "laichau\n",
            "2\n",
            "1\n",
            "thanhhoa\n",
            "haichau \n",
            "1\n",
            "binhdinh\n",
            "hoangmai \n",
            "Input:  Khóm 1,Thị Trấn Tam Bình, Vĩnh Long\n",
            "Sanitized:  ['vinhlong', 'ambinh', 'khom1']\n",
            "Result:  {'province': 'Vĩnh Long', 'district': 'Tam Bình', 'ward': '14'}\n",
            "Answer:  {'province': 'Vĩnh Long', 'district': 'Tam Bình', 'ward': ''}\n",
            "----\n",
            "2\n",
            "1\n",
            "binhthuan\n",
            "1\n",
            "thaibinh\n",
            "gthanh \n",
            "1\n",
            "thanhhoa\n",
            "ninhbinh vangiang\n",
            "Input:  Thôn Đồng Lực Hoàng Lâu, Tam Dương, Vĩnh Phúc\n",
            "Sanitized:  ['vinhphuc', 'tamduong', 'choanglau']\n",
            "Result:  {'province': 'Vĩnh Phúc', 'district': 'Tam Đường', 'ward': 'Hoàng Lâu'}\n",
            "Answer:  {'province': 'Vĩnh Phúc', 'district': 'Tam Dương', 'ward': 'Hoàng Lâu'}\n",
            "----\n",
            "1\n",
            "botrachquangbinh\n",
            "1\n",
            "ninhbinh\n",
            "1\n",
            "thanhhoa\n",
            "1\n",
            "hoanghoathanhhoa\n",
            "1\n",
            "lethuyquangbinh\n",
            "thanhhoa dongtho\n",
            "Input:  Tân Trung Tân Thành, Tân Châu, Tây Ninh\n",
            "Sanitized:  ['tayninh', 'tanchau', 'gtanthanh']\n",
            "Result:  {'province': 'Tây Ninh', 'district': 'Tân Châu', 'ward': 'Tân Thạnh'}\n",
            "Answer:  {'province': 'Tây Ninh', 'district': 'Tân Châu', 'ward': 'Tân Thành'}\n",
            "----\n",
            "12 thoian\n",
            "1\n",
            "thachthanhthanhhoa\n",
            "1\n",
            "viethhiphutho\n",
            "1\n",
            "tuyenquang\n",
            "1 cogiang\n",
            "Input:  Phố Tân Mỹ Thị trấn Me, Gia Viễn, Ninh Bình\n",
            "Sanitized:  ['ninhbinh', 'giavien', 'thitranme']\n",
            "Result:  {'province': 'Ninh Bình', 'district': 'Gia Viễn', 'ward': 'Thới An'}\n",
            "Answer:  {'province': 'Ninh Bình', 'district': 'Gia Viễn', 'ward': 'Me'}\n",
            "----\n",
            "g tuyen\n",
            "Input:  P.Phan thiết, Thị Xã Tuyên Quang, Tuyên Quang\n",
            "Sanitized:  ['tuyenquang', 'phanthiet', '']\n",
            "Result:  {'province': 'Tuyên Quang', 'district': 'Phan Thiết', 'ward': ''}\n",
            "Answer:  {'province': 'Tuyên Quang', 'district': 'Tuyên Quang', 'ward': 'Phan Thiết'}\n",
            "----\n",
            "10 3\n",
            "2\n",
            "2 \n",
            "1\n",
            "camle.danang.\n",
            "1\n",
            "tuyenquang\n",
            "1\n",
            "binhdinh.\n",
            "10 \n",
            "ghung \n",
            "2\n",
            "6 12\n",
            "Input:  Van Điểm, H hường TLín, Thành phốHa Nội\n",
            "Sanitized:  ['hanoi', 'ngtlin', 'hhuong']\n",
            "Result:  {'province': 'Hà Nội', 'district': 'Nghi Sơn', 'ward': '4'}\n",
            "Answer:  {'province': 'Hà Nội', 'district': 'Thường Tín', 'ward': 'Vạn Điểm'}\n",
            "----\n",
            "1\n",
            "hanminh\n",
            "camrah \n",
            "Input:  X Cam Bình, Thành FhốCam Rah,  Khánh Hòa\n",
            "Sanitized:  ['khanhhoa', 'camrah', 'xcambinh']\n",
            "Result:  {'province': 'Khánh Hòa', 'district': 'Cam Ranh', 'ward': 'Cẩm Bình'}\n",
            "Answer:  {'province': 'Khánh Hòa', 'district': 'Cam Ranh', 'ward': 'Cam Bình'}\n",
            "----\n",
            "1\n",
            "daklak\n",
            "1\n",
            "dongnai\n",
            "Input:  X. HoDng Quỳ,,9hanh Hóa\n",
            "Sanitized:  ['9hanhhoa', '', 'hodngquy']\n",
            "Result:  {'province': 'Khánh Hòa', 'district': '', 'ward': 'Hoằng Quỳ'}\n",
            "Answer:  {'province': 'Thanh Hóa', 'district': '', 'ward': 'Hoằng Quỳ'}\n",
            "----\n",
            "Input:  XVnh Hung, , T.Thanh Hóa\n",
            "Sanitized:  ['thanhhoa', '', 'xvnhhung']\n",
            "Result:  {'province': 'Thanh Hóa', 'district': '', 'ward': 'Vĩnh Hưng'}\n",
            "Answer:  {'province': 'Thanh Hóa', 'district': '', 'ward': 'Vĩnh Hùng'}\n",
            "----\n",
            "Input:  X.Tăng Thanh, H Yên Thành, \n",
            "Sanitized:  ['', 'thanh', 'tangthanh']\n",
            "Result:  {'province': '', 'district': 'Vị Thanh', 'ward': 'Tăng Thành'}\n",
            "Answer:  {'province': '', 'district': 'Yên Thành', 'ward': 'Tăng Thành'}\n",
            "----\n",
            "Input:  XãTrung Lập,  Vĩnh Bảo,7 \n",
            "Sanitized:  ['7', 'vinhbao', 'trunglap']\n",
            "Result:  {'province': 'Hồ Chí Minh', 'district': 'Vĩnh Bảo', 'ward': 'Trung Lập'}\n",
            "Answer:  {'province': '', 'district': 'Vĩnh Bảo', 'ward': 'Trung Lập'}\n",
            "----\n",
            "1\n",
            "utravinh\n",
            "1\n",
            "quangnam\n",
            "Input:  Fmễ Trì, Nam Từ Liêm, Thành phố HN\n",
            "Sanitized:  ['', 'namtuliem', 'fmetri']\n",
            "Result:  {'province': '', 'district': 'Nam Từ Liêm', 'ward': 'Mễ Trì'}\n",
            "Answer:  {'province': 'Hà Nội', 'district': 'Nam Từ Liêm', 'ward': 'Mễ Trì'}\n",
            "----\n",
            "Input:  F.07, Q6, \n",
            "Sanitized:  ['', 'q6', 'f.07']\n",
            "Result:  {'province': '', 'district': '', 'ward': '07'}\n",
            "Answer:  {'province': '', 'district': '6', 'ward': '07'}\n",
            "----\n",
            "Input:   Long Thắng, Huyn Lai ung, \n",
            "Sanitized:  ['', 'laiung', 'huynla']\n",
            "Result:  {'province': '', 'district': 'Lai Vung', 'ward': 'Huy Hạ'}\n",
            "Answer:  {'province': '', 'district': 'Lai Vung', 'ward': 'Long Thắng'}\n",
            "----\n",
            "Input:  XãtrBung Thanh,,TThanh Hóa\n",
            "Sanitized:  ['hanhhoa', '', 'trungthanh']\n",
            "Result:  {'province': 'Khánh Hòa', 'district': '', 'ward': 'Trung Thành'}\n",
            "Answer:  {'province': 'Thanh Hóa', 'district': '', 'ward': 'Trung Thành'}\n",
            "----\n",
            "Input:  Phường 04,,Thành phốHồ Chi Minh\n",
            "Sanitized:  ['ochiminh', '', '4']\n",
            "Result:  {'province': 'Hồ Chí Minh', 'district': '', 'ward': '4'}\n",
            "Answer:  {'province': 'Hồ Chí Minh', 'district': '', 'ward': '04'}\n",
            "----\n",
            "Input:  P.Văn Đẩu, qKiến An, ThànhMphố Hải Phòng\n",
            "Sanitized:  ['hohaiphong', 'thanhmpho', 'qkienan']\n",
            "Result:  {'province': 'Hải Phòng', 'district': 'Thanh Hóa', 'ward': 'Kiên Thành'}\n",
            "Answer:  {'province': 'Hải Phòng', 'district': 'Kiến An', 'ward': 'Văn Đẩu'}\n",
            "----\n",
            "Input:  P. Quảng Thọ,T.P Sầm Swn,TY. thanh Hóa\n",
            "Sanitized:  ['hanhhoa', 'ty.tha', 'samswn']\n",
            "Result:  {'province': 'Khánh Hòa', 'district': 'Tuy Hoà', 'ward': 'Hà Mãn'}\n",
            "Answer:  {'province': 'Thanh Hóa', 'district': 'Sầm Sơn', 'ward': 'Quảng Thọ'}\n",
            "----\n",
            "1\n",
            "ixaquangyent.quangninh\n",
            "Input:  X. TErường Thịnh,h Ứng Hòa, Hà Nội\n",
            "Sanitized:  ['hanoi', 'hunghoa', 'truongthinh']\n",
            "Result:  {'province': 'Hà Nội', 'district': 'Hưng Hà', 'ward': 'Trường Thịnh'}\n",
            "Answer:  {'province': 'Hà Nội', 'district': 'Ứng Hòa', 'ward': 'Trường Thịnh'}\n",
            "----\n",
            "Input:  X.H Mỗ, Đan PhTượng,\n",
            "Sanitized:  ['', 'danphuong', 'mo']\n",
            "Result:  {'province': '', 'district': 'Đan Phượng', 'ward': ''}\n",
            "Answer:  {'province': '', 'district': 'Đan Phượng', 'ward': 'Hạ Mỗ'}\n",
            "----\n",
            "2\n",
            "Input:  Thị trấn Tân Phong, , TThanh Hóa\n",
            "Sanitized:  ['hanhhoa', '', 'anphong']\n",
            "Result:  {'province': 'Khánh Hòa', 'district': '', 'ward': 'Tân Phong'}\n",
            "Answer:  {'province': 'Thanh Hóa', 'district': '', 'ward': 'Tân Phong'}\n",
            "----\n",
            "1\n",
            "nhtiengiang\n",
            "1\n",
            "xtquangnam\n",
            "Input:   eăn Tiến, Yên Lạc, vĩnh P0húc\n",
            "Sanitized:  ['vinhp0huc', 'yenlac', 'eantien']\n",
            "Result:  {'province': 'Vĩnh Phúc', 'district': 'Yên Lạc', 'ward': 'An Tiến'}\n",
            "Answer:  {'province': 'Vĩnh Phúc', 'district': 'Yên Lạc', 'ward': 'Văn Tiến'}\n",
            "----\n",
            "Input:  Diên Thạnh,,T Khabnh Hòa\n",
            "Sanitized:  ['khanhhoa', '', 'dienthanh']\n",
            "Result:  {'province': 'Khánh Hòa', 'district': '', 'ward': 'Diễn Thành'}\n",
            "Answer:  {'province': 'Khánh Hòa', 'district': '', 'ward': 'Diên Thạnh'}\n",
            "----\n",
            "Input:  XThạch Xuâ,Thạch Hà,T. Hà Tĩnh\n",
            "Sanitized:  ['hatinh', 'thachha', 'xthachxua']\n",
            "Result:  {'province': 'Hà Tĩnh', 'district': 'Thạch Hà', 'ward': 'Thạch Xá'}\n",
            "Answer:  {'province': 'Hà Tĩnh', 'district': 'Thạch Hà', 'ward': 'Thạch Xuân'}\n",
            "----\n",
            "Input:  , Tân Phươc, Tin GJiang\n",
            "Sanitized:  ['gjiang', 'tanphuoc', '']\n",
            "Result:  {'province': 'An Giang', 'district': 'Tân Phước', 'ward': ''}\n",
            "Answer:  {'province': 'Tiền Giang', 'district': 'Tân Phước', 'ward': ''}\n",
            "----\n",
            "g vu\n",
            "Input:   Đức Lĩnh,Vũ Quang,\n",
            "Sanitized:  ['', 'duclinh', '']\n",
            "Result:  {'province': '', 'district': 'Đức Linh', 'ward': ''}\n",
            "Answer:  {'province': '', 'district': 'Vũ Quang', 'ward': 'Đức Lĩnh'}\n",
            "----\n",
            "Input:  Xã Uar, Krông Pa, Tỉnh Gia Lai\n",
            "Sanitized:  ['gialai', 'krongpa', 'ar']\n",
            "Result:  {'province': 'Gia Lai', 'district': 'Krông Pa', 'ward': ''}\n",
            "Answer:  {'province': 'Gia Lai', 'district': 'Krông Pa', 'ward': 'Uar'}\n",
            "----\n",
            "1\n",
            "thanhhoa\n",
            "Input:  P Thủy Châu,T.X. hươngThủy,Thừa.t.Huế\n",
            "Sanitized:  ['', 'huongthuy', 'pthuychau']\n",
            "Result:  {'province': '', 'district': 'Hương Thủy', 'ward': 'Thủy Châu'}\n",
            "Answer:  {'province': 'Thừa Thiên Huế', 'district': 'Hương Thủy', 'ward': 'Thủy Châu'}\n",
            "----\n",
            "------------------------------\n",
            "---- OVERTIME TESTS ----\n",
            "Empty DataFrame\n",
            "Columns: [text, time_sec]\n",
            "Index: []\n",
            "----\n",
            "TEAM_NAME = 'DEFAULT_NAME'\n",
            "EXCEL_FILE = 'DEFAULT_NAME.xlsx'\n",
            "   correct  total  score / 10  max_time_sec  avg_time_sec\n",
            "0     1163   1350        8.61        0.0858        0.0281\n",
            "Province: 419 / 450\n",
            "District: 383 / 450\n",
            "Ward: 361 / 450\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "# NOTE: DO NOT change this cell\n",
        "# This cell is for scoring\n",
        "\n",
        "TEAM_NAME = 'DEFAULT_NAME'  # This should be your team name\n",
        "EXCEL_FILE = f'{TEAM_NAME}.xlsx'\n",
        "\n",
        "import json\n",
        "import time\n",
        "with open('test.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# data = [\n",
        "#     {\n",
        "#         \"text\": \"31B Sư Vạn Hạnh, Phường 3 Quận 10, TP. Hồ Chí Minh\",\n",
        "#         \"result\": {'province': 'Hồ Chí Minh', 'district': '10', 'ward': '3'}\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "\n",
        "summary_only = True\n",
        "df = []\n",
        "solution = Solution()\n",
        "timer = []\n",
        "correct = 0\n",
        "ok_p, ok_d, ok_w = 0, 0, 0\n",
        "for test_idx, data_point in enumerate(data):\n",
        "    address = data_point[\"text\"]\n",
        "    ok = 0\n",
        "    try:\n",
        "        start = time.perf_counter_ns()\n",
        "        result, sanitized = solution.process(address)\n",
        "        answer = data_point[\"result\"]\n",
        "        finish = time.perf_counter_ns()\n",
        "        timer.append(finish - start)\n",
        "        ok += int(answer[\"province\"] == result[\"province\"])\n",
        "        ok_p += int(answer[\"province\"] == result[\"province\"])\n",
        "        ok += int(answer[\"district\"] == result[\"district\"])\n",
        "        ok_d += int(answer[\"district\"] == result[\"district\"])\n",
        "        ok_w += int(answer[\"ward\"] == result[\"ward\"])\n",
        "        ok += int(answer[\"ward\"] == result[\"ward\"])\n",
        "        df.append([\n",
        "            test_idx,\n",
        "            address,\n",
        "            answer[\"province\"],\n",
        "            result[\"province\"],\n",
        "            int(answer[\"province\"] == result[\"province\"]),\n",
        "            answer[\"district\"],\n",
        "            result[\"district\"],\n",
        "            int(answer[\"district\"] == result[\"district\"]),\n",
        "            answer[\"ward\"],\n",
        "            result[\"ward\"],\n",
        "            int(answer[\"ward\"] == result[\"ward\"]),\n",
        "            ok,\n",
        "            timer[-1] / 1_000_000_000,\n",
        "        ])\n",
        "        # TODO: REMOVE\n",
        "        if ok < 3 and len(address.split(\",\")) == 3:\n",
        "          print(\"Input: \", address)\n",
        "          print(\"Sanitized: \", sanitized)\n",
        "          print(\"Result: \", result)\n",
        "          print(\"Answer: \", {\n",
        "              \"province\": answer[\"province\"],\n",
        "              \"district\": answer[\"district\"],\n",
        "              \"ward\": answer[\"ward\"]\n",
        "          })\n",
        "          print(\"----\")\n",
        "    except Exception as e:\n",
        "        print(\"*****Error*****\", address, e, e.with_traceback)\n",
        "        df.append([\n",
        "            test_idx,\n",
        "            address,\n",
        "            answer[\"province\"],\n",
        "            \"EXCEPTION\",\n",
        "            0,\n",
        "            answer[\"district\"],\n",
        "            \"EXCEPTION\",\n",
        "            0,\n",
        "            answer[\"ward\"],\n",
        "            \"EXCEPTION\",\n",
        "            0,\n",
        "            0,\n",
        "            0,\n",
        "        ])\n",
        "        # any failure count as a zero correct\n",
        "        pass\n",
        "    correct += ok\n",
        "\n",
        "\n",
        "    if not summary_only:\n",
        "        # responsive stuff\n",
        "        print(f\"Test {test_idx:5d}/{len(data):5d}\")\n",
        "        print(f\"Correct: {ok}/3\")\n",
        "        print(f\"Time Executed: {timer[-1] / 1_000_000_000:.4f}\")\n",
        "\n",
        "# print(province_correct)\n",
        "print(f\"-\"*30)\n",
        "total = len(data) * 3\n",
        "score_scale_10 = round(correct / total * 10, 2)\n",
        "if len(timer) == 0:\n",
        "    timer = [0]\n",
        "max_time_sec = round(max(timer) / 1_000_000_000, 4)\n",
        "avg_time_sec = round((sum(timer) / len(timer)) / 1_000_000_000, 4)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df2 = pd.DataFrame(\n",
        "    [[correct, total, score_scale_10, max_time_sec, avg_time_sec]],\n",
        "    columns=['correct', 'total', 'score / 10', 'max_time_sec', 'avg_time_sec',],\n",
        ")\n",
        "\n",
        "columns = [\n",
        "    'ID',\n",
        "    'text',\n",
        "    'province',\n",
        "    'province_student',\n",
        "    'province_correct',\n",
        "    'district',\n",
        "    'district_student',\n",
        "    'district_correct',\n",
        "    'ward',\n",
        "    'ward_student',\n",
        "    'ward_correct',\n",
        "    'total_correct',\n",
        "    'time_sec',\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "df.columns = columns\n",
        "print('---- OVERTIME TESTS ----')\n",
        "print(df[df['time_sec'] > 0.1][['text', 'time_sec']])\n",
        "print('----')\n",
        "\n",
        "print(f'{TEAM_NAME = }')\n",
        "print(f'{EXCEL_FILE = }')\n",
        "print(df2)\n",
        "print(\"Province:\", ok_p, \"/\", len(data))\n",
        "print(\"District:\", ok_d, \"/\", len(data))\n",
        "print(\"Ward:\", ok_w, \"/\", len(data))\n",
        "\n",
        "!pip install xlsxwriter\n",
        "writer = pd.ExcelWriter(EXCEL_FILE, engine='xlsxwriter')\n",
        "df2.to_excel(writer, index=False, sheet_name='summary')\n",
        "df.to_excel(writer, index=False, sheet_name='details')\n",
        "writer.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FetalHAdbxT5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}